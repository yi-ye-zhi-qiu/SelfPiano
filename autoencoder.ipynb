{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "autoencoder.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPhOQ28o4p7x6jg2iW1C8uW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yi-ye-zhi-qiu/kitchensoundscapes/blob/main/autoencoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RV124vOu1O1B",
        "outputId": "c7342358-9875-481a-eb56-aeafeb2814d6"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ME1YfgI7_Lq-"
      },
      "source": [
        "# Autoencoder\n",
        "\n",
        "\n",
        "\n",
        "1.   Get note/chords data from midi folder of files\n",
        "*Reproducing?* Create a \"music\" folder in your Drive, and \"training_songs\" folder in that. Store training data there\n",
        "2.   Convert training data into a format Autoencoder can use (one hot encode notes/chords, etc.)\n",
        "3.   Train Autoencoder\n",
        "4.   Let Autoencoder \"reconstruct\" the \"image\" of data that we feed it. If you feed it a song called \"tomato soup\", it will reconstruct tomato soup. So on and so forth.\n",
        "5.   Take that reconstruction, and save as a generated MIDI file named as today's date/time.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3X3Z6o2Z_VmV"
      },
      "source": [
        "from keras.utils import np_utils\n",
        "from keras.layers import Input, Dense, Flatten, Reshape\n",
        "from keras import layers\n",
        "from keras.models import Model\n",
        "from keras.optimizers import RMSprop\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from music21 import converter, instrument, note, chord, stream\n",
        "import pickle\n",
        "import os\n",
        "import numpy as np"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXva6vih9xzg"
      },
      "source": [
        "Get notes from MIDI files\n",
        "- Note: music21 differentiates *chords* with *notes*, **chords** (the occurrence of multiple notes @ once) are interpreted as 'note_one'.'note_two', where as **notes** are interpreted as 'note_one' or 'note_two'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDoz5hER_Mx2"
      },
      "source": [
        "def get_notes(path):\n",
        "\n",
        "    notes = []\n",
        "    durations = []\n",
        "    for filename in os.listdir(path):\n",
        "      file = path + \"/\" + filename\n",
        "      print(\"Parsing\", file)\n",
        "\n",
        "      midi = converter.parse(file)\n",
        "      need_parse = midi.flat.notes\n",
        "\n",
        "      for i in need_parse:\n",
        "          if isinstance(i, note.Note):\n",
        "              notes.append(str(i.pitch))\n",
        "              durations.append(str(i.duration.quarterLength))\n",
        "          elif isinstance(i, chord.Chord):\n",
        "              #This will give chords as numbers: notes.append('.'.join(str(n) for n in i.normalOrder))\n",
        "              notes.append('.'.join(str(n) for n in i.pitches))\n",
        "              durations.append(str(i.duration.quarterLength))\n",
        "\n",
        "    return notes, durations\n"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iAU0fznX_MvO",
        "outputId": "4d6114ab-4066-4a74-f0b3-657b961121a5"
      },
      "source": [
        "notes_from_here_please = \"/content/drive/My Drive/notebooks/music/training_songs\"\n",
        "notes, durations = get_notes(notes_from_here_please)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parsing /content/drive/My Drive/notebooks/music/training_songs/breadknife.mid\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wkW9ONRF-7jI"
      },
      "source": [
        "what does notes look like?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZvsHvO5-ITC",
        "outputId": "7cfed941-fa96-4b38-84e3-26216f34123f"
      },
      "source": [
        "print('printing first part of notes for you...')\n",
        "notes[1:10]"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "printing first part of notes for you...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['E-4', 'E4', 'E7.G#6', 'G#3.E4', 'B3', 'B5.G#6', 'A3.E4.C#4', 'B4', 'E-5']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5qgOv_w41nnn"
      },
      "source": [
        "Helper functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARWsYhtz1mbT"
      },
      "source": [
        "def get_key(val, dictionary):\n",
        "  \"\"\"\n",
        "  Get key from a val in a given dictionary's items\n",
        "  \"\"\"\n",
        "  for key, value in dictionary.items():\n",
        "        if val == value:\n",
        "            return key\n",
        "\n",
        "  return \"key DNE\""
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxMjy4RK649f"
      },
      "source": [
        "def list_to_dict(x):\n",
        "  \"\"\"\n",
        "  Converts list to dict or list of lists to dict\n",
        "  \"\"\"\n",
        "  try: #if JUST a list as input\n",
        "    unique = sorted(set([item for item in x]))\n",
        "    print(len(unique),' unique notes put into dictionary')\n",
        "    Dict = {}\n",
        "    for i in range(0, len(unique)):\n",
        "      Dict[unique[i]] = i\n",
        "    #Dict = dict((i, j) for j, i in enumerate(x))\n",
        "    return Dict\n",
        "\n",
        "  except: #if LIST input contains LIST (if input is a list of lists...)\n",
        "    new_x = []\n",
        "    for i, j in enumerate(x):\n",
        "      if isinstance(j, list): \n",
        "        for k in j:\n",
        "          new_x.append(k)\n",
        "      else:\n",
        "        new_x.append(j)\n",
        "\n",
        "    return list_to_dict(new_x)"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvQ5yJHh1arA"
      },
      "source": [
        "def construct_melody(x, dictionary, sequence_length):\n",
        "  \"\"\"\n",
        "  Constructs \"windows\" for melody, \n",
        "  segments of notes (of len sequence_length) to use as input, \n",
        "  since we encode each note using a dictionary. \n",
        "\n",
        "  If your collab crashes a lot, this is probably due to a bad dictionary. \n",
        "  The autoencoder should be able to handle longer sequences. \n",
        "  \"\"\"\n",
        "  print('Constructing segments of notes as melodies to use as input, since we encode each note using a dictionary (note_to_int)')\n",
        "  result = []\n",
        "  for i in range(0, len(x) - sequence_length):\n",
        "    sequence_window = x[i:i + sequence_length]\n",
        "    result.append([dictionary[char] for char in sequence_window])\n",
        "  return result"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XIEKPXuE1qdK"
      },
      "source": [
        "Get training data in a format Autoencoder can use"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xXcY3fX1bPj"
      },
      "source": [
        "def get_TrainingData(notes, durations, sequence_length):\n",
        "\n",
        "    print('Desired sequence length is', sequence_length)\n",
        "\n",
        "    note_to_int = list_to_dict(notes)\n",
        "    #duration_to_int = list_to_dict(durations)\n",
        "    print('Note dictionary, \\n',note_to_int)\n",
        "    #print('Duration dictionary, \\n',duration_to_int)\n",
        "\n",
        "    Notes_ = construct_melody(notes, note_to_int, sequence_length)\n",
        "    #durations_ = construct_melody(durations, duration_to_int, sequence_length)\n",
        "\n",
        "    Notes_ = np_utils.to_categorical(Notes_).transpose(0,2,1)\n",
        "    Notes_ = np.array(Notes_, np.float)\n",
        "    print('notes->Notes_; one-hot encoded; turned into a numpy array')\n",
        "\n",
        "    return note_to_int, Notes_#, durations_"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_QcIH0GB1dJ7",
        "outputId": "0ad49b40-dd6c-4adf-d0e6-754cafe26632"
      },
      "source": [
        "sequence_length = 60\n",
        "int_to_note, Notes_ = get_TrainingData(notes, durations, sequence_length)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Desired sequence length is 60\n",
            "112  unique notes put into dictionary\n",
            "Note dictionary, \n",
            " {'A1': 0, 'A2': 1, 'A2.C#3': 2, 'A3': 3, 'A3.C#4': 4, 'A3.E-3': 5, 'A3.E4.C#4': 6, 'A3.G#3': 7, 'A4': 8, 'A5': 9, 'A6': 10, 'A6.A5': 11, 'B-2': 12, 'B-4': 13, 'B-5': 14, 'B1': 15, 'B2': 16, 'B2.A3': 17, 'B2.E-3': 18, 'B3': 19, 'B3.C#4.E-4': 20, 'B4': 21, 'B4.B3': 22, 'B4.E4': 23, 'B5': 24, 'B5.B4': 25, 'B5.G#5': 26, 'B5.G#6': 27, 'B6': 28, 'B6.E-6': 29, 'B6.F#6.G#6': 30, 'C#2': 31, 'C#3': 32, 'C#3.F#2': 33, 'C#4': 34, 'C#4.A3': 35, 'C#4.E4': 36, 'C#5': 37, 'C#5.C#4': 38, 'C#5.E4': 39, 'C#5.E5': 40, 'C#6': 41, 'C#6.A5': 42, 'C#6.E5': 43, 'C#6.E6': 44, 'C#7': 45, 'C#7.E6': 46, 'E-3': 47, 'E-3.G#3': 48, 'E-4': 49, 'E-4.F#3': 50, 'E-4.G#3': 51, 'E-5': 52, 'E-5.B4': 53, 'E-6': 54, 'E-6.B5': 55, 'E-6.F#6': 56, 'E-7': 57, 'E-7.E-6': 58, 'E1': 59, 'E2': 60, 'E3': 61, 'E3.E4': 62, 'E4': 63, 'E4.C#4': 64, 'E4.C#5': 65, 'E4.E3': 66, 'E5': 67, 'E6': 68, 'E7.G#6': 69, 'F#1.E4': 70, 'F#2': 71, 'F#3': 72, 'F#3.A3': 73, 'F#3.E4': 74, 'F#4': 75, 'F#4.F#3': 76, 'F#4.G#3': 77, 'F#4.G#4': 78, 'F#5': 79, 'F#5.E5': 80, 'F#5.F#4': 81, 'F#6': 82, 'F3': 83, 'F5': 84, 'G#1': 85, 'G#2': 86, 'G#2.E3': 87, 'G#3': 88, 'G#3.C#4': 89, 'G#3.E3': 90, 'G#3.E4': 91, 'G#3.G#4': 92, 'G#4': 93, 'G#4.B3': 94, 'G#4.B4': 95, 'G#4.F#4': 96, 'G#4.G#5': 97, 'G#4.G#5.B4': 98, 'G#5': 99, 'G#5.B4': 100, 'G#5.B4.G#4': 101, 'G#5.B5': 102, 'G#5.E-5': 103, 'G#5.G#4': 104, 'G#6': 105, 'G#6.B5': 106, 'G#6.B5.G#5': 107, 'G#6.E-6': 108, 'G#6.F#6': 109, 'G#6.G#5.B5': 110, 'G5': 111}\n",
            "Constructing segments of notes as melodies to use as input, since we encode each note using a dictionary (note_to_int)\n",
            "notes->Notes_; one-hot encoded; turned into a numpy array\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eE0x1g_S9JEX"
      },
      "source": [
        "Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YnZ08OCw_Msm"
      },
      "source": [
        "\"\"\" Seeding \"\"\"\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "\"\"\" Hyperparameters \"\"\"\n",
        "latent_dim = 2\n",
        "input_sample = Notes_.shape[0]\n",
        "input_notes = Notes_.shape[1]\n",
        "input_dim = input_notes * sequence_length\n",
        "num_epochs = 10\n"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8PHqPixD9QID"
      },
      "source": [
        "Run Autoencoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9zL5D-MS9RpE",
        "outputId": "5b5da8c5-a6e7-43f1-a9d4-37a4a6e62f92"
      },
      "source": [
        "def get_autoencoder(input_sample, input_notes, input_dim, latent_dim):\n",
        "\n",
        "    ##Encoder\n",
        "    EncInput = Input(shape= (input_dim))\n",
        "    Enc = Dense(latent_dim, activation = 'tanh')(EncInput)\n",
        "    print(Enc)\n",
        "    encode = Model(EncInput, Enc)\n",
        "\n",
        "    ##Decoder\n",
        "    DecInput = Input(shape= (latent_dim))\n",
        "    Dec = Dense(input_dim, activation = 'sigmoid')(DecInput)\n",
        "    print(Dec)\n",
        "    decode = Model(DecInput, Dec)\n",
        "\n",
        "    ##Autoencoder\n",
        "    autoencoder = Model(EncInput, decode(Enc))\n",
        "    autoencoder.compile(loss = 'binary_crossentropy', optimizer=RMSprop(learning_rate=0.000013))\n",
        "\n",
        "    return autoencoder, decode\n",
        "\n",
        "autoencoder, Decode_r = get_autoencoder(input_sample, input_notes, input_dim, latent_dim)\n",
        "fit_on = Notes_.reshape(input_sample, input_dim)\n",
        "autoencoder.fit(fit_on, fit_on, epochs=num_epochs)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "KerasTensor(type_spec=TensorSpec(shape=(None, 2), dtype=tf.float32, name=None), name='dense_2/Tanh:0', description=\"created by layer 'dense_2'\")\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 6720), dtype=tf.float32, name=None), name='dense_3/Sigmoid:0', description=\"created by layer 'dense_3'\")\n",
            "Epoch 1/10\n",
            "13/13 [==============================] - 1s 8ms/step - loss: 0.6931\n",
            "Epoch 2/10\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.6930\n",
            "Epoch 3/10\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.6929\n",
            "Epoch 4/10\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.6928\n",
            "Epoch 5/10\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.6927\n",
            "Epoch 6/10\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.6926\n",
            "Epoch 7/10\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.6925\n",
            "Epoch 8/10\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.6924\n",
            "Epoch 9/10\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.6923\n",
            "Epoch 10/10\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.6921\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f3f315cc7d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfU_KJoN1vJy"
      },
      "source": [
        "Decode"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ULQ8AdU01utq",
        "outputId": "18a0d099-9d42-4109-fd04-a2d2823a05c2"
      },
      "source": [
        "def decode(int_to_note, Decode_r):\n",
        "\n",
        "    ##Computer's melody\n",
        "    ComputersMelody = Decode_r(np.random.normal(size=(1, latent_dim))).numpy().reshape(input_notes, sequence_length).argmax(0)\n",
        "    print('Output shape (the length of your song) is \\n',np.array(ComputersMelody).shape)\n",
        "    print('Raw output (prior to passing back to dictionary) is', ComputersMelody)\n",
        "    MelodyNotes = [get_key(c, int_to_note) for c in ComputersMelody]\n",
        "    print('After decoding int->note, we get \\n',MelodyNotes)\n",
        "    return MelodyNotes\n",
        "\n",
        "MelodyNotes = decode(int_to_note, Decode_r)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Output shape (the length of your song) is \n",
            " (60,)\n",
            "Raw output (prior to passing back to dictionary) is [ 39  79  30  56  17  93  20  76  95  90  75  82  74  79  78 100  28 105\n",
            "  32  27  88  72  25  28   9   8  23  31 107  29  11  58 100  73  88  34\n",
            "  90 101  83  60  69  84  55  53   0  47  36  84  24  48  10  80  23  38\n",
            "   2  90   9   8  93  97]\n",
            "After decoding int->note, we get \n",
            " ['C#5.E4', 'F#5', 'B6.F#6.G#6', 'E-6.F#6', 'B2.A3', 'G#4', 'B3.C#4.E-4', 'F#4.F#3', 'G#4.B4', 'G#3.E3', 'F#4', 'F#6', 'F#3.E4', 'F#5', 'F#4.G#4', 'G#5.B4', 'B6', 'G#6', 'C#3', 'B5.G#6', 'G#3', 'F#3', 'B5.B4', 'B6', 'A5', 'A4', 'B4.E4', 'C#2', 'G#6.B5.G#5', 'B6.E-6', 'A6.A5', 'E-7.E-6', 'G#5.B4', 'F#3.A3', 'G#3', 'C#4', 'G#3.E3', 'G#5.B4.G#4', 'F3', 'E2', 'E7.G#6', 'F5', 'E-6.B5', 'E-5.B4', 'A1', 'E-3', 'C#4.E4', 'F5', 'B5', 'E-3.G#3', 'A6', 'F#5.E5', 'B4.E4', 'C#5.C#4', 'A2.C#3', 'G#3.E3', 'A5', 'A4', 'G#4', 'G#4.G#5']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r0NWsVnD-YfP"
      },
      "source": [
        "Array of notes/chords -> song"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-rbSvED3-cWB"
      },
      "source": [
        "Song will save as today's date in your \"music\" folder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1GRNVk1C-e5B",
        "outputId": "5625b5cd-5ddd-4f1f-e7d6-36aa73c85cb6"
      },
      "source": [
        "from datetime import datetime\n",
        "\n",
        "#datetime object containing current date and time\n",
        "now = datetime.now()\n",
        " \n",
        "# dd/mm/YY H:M:S\n",
        "dt_string = now.strftime(\"%d/%m/%Y %H:%M:%S\")\n",
        "today = dt_string.replace('/', '').replace(' ', '.').replace(':', '')\n",
        "print(\"Current date and time (file will save as this) =\", today)\t"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Current date and time (file will save as this) = 24032021.161432\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "4O-f69j9_MpP",
        "outputId": "60cf3a5a-648f-4db1-9104-973644ffab2a"
      },
      "source": [
        "def give_song(MelodyNotes, today):\n",
        "    s_obj = stream.Stream()\n",
        "    s_obj.append(instrument.Piano())\n",
        "\n",
        "    print(MelodyNotes)\n",
        "\n",
        "    count = 0\n",
        "    for x in MelodyNotes:\n",
        "      if x == \"key doesn't exist\":\n",
        "        count += 1\n",
        "        continue;\n",
        "      else:\n",
        "        if '.' in x:\n",
        "          s_obj.append(chord.Chord(x.replace('.', ' ')))\n",
        "        else:\n",
        "          s_obj.append(note.Note(x))\n",
        "\n",
        "    print('Sorry, I had to erase', count, 'notes or chords that I could not find in your note-to-int dictionary')\n",
        "    \n",
        "    #Change to where you want to save this file\n",
        "    save_to ='/content/drive/My Drive/notebooks/music/'\n",
        "\n",
        "    s_obj.write('midi', fp=save_to + today + '.mid')\n",
        "    print('Generated a file in your', save_to, 'path called', str(today)+'.mid')\n",
        "    return 'Done! Thanks!'\n",
        "\n",
        "give_song(MelodyNotes, today)"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['C#5.E4', 'F#5', 'B6.F#6.G#6', 'E-6.F#6', 'B2.A3', 'G#4', 'B3.C#4.E-4', 'F#4.F#3', 'G#4.B4', 'G#3.E3', 'F#4', 'F#6', 'F#3.E4', 'F#5', 'F#4.G#4', 'G#5.B4', 'B6', 'G#6', 'C#3', 'B5.G#6', 'G#3', 'F#3', 'B5.B4', 'B6', 'A5', 'A4', 'B4.E4', 'C#2', 'G#6.B5.G#5', 'B6.E-6', 'A6.A5', 'E-7.E-6', 'G#5.B4', 'F#3.A3', 'G#3', 'C#4', 'G#3.E3', 'G#5.B4.G#4', 'F3', 'E2', 'E7.G#6', 'F5', 'E-6.B5', 'E-5.B4', 'A1', 'E-3', 'C#4.E4', 'F5', 'B5', 'E-3.G#3', 'A6', 'F#5.E5', 'B4.E4', 'C#5.C#4', 'A2.C#3', 'G#3.E3', 'A5', 'A4', 'G#4', 'G#4.G#5']\n",
            "Sorry, I had to erase 0 notes or chords that I could not find in your note-to-int dictionary\n",
            "Generated a file in your /content/drive/My Drive/notebooks/music/ path called 24032021.161432.mid\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Done! Thanks!'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f56TyEgV_Mfh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}