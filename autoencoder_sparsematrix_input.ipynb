{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "autoencoder_sparsematrix_input.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP2j51/Rzi4jtQJUoI0hn1Z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yi-ye-zhi-qiu/kitchensoundscapes/blob/main/autoencoder_sparsematrix_input.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "feukEmGZ2AH0",
        "outputId": "39b462a3-7d12-4615-bb53-3042a5e8635c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iNYk55cH1751"
      },
      "source": [
        "# Autoencoder (sparse matrix input)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qEKtAotD12-l"
      },
      "source": [
        "from keras.utils import np_utils\n",
        "from keras.layers import Input, Dense, Flatten, Reshape\n",
        "from keras import layers\n",
        "from keras.models import Model, Sequential\n",
        "from keras.optimizers import RMSprop \n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from music21 import converter, instrument, note, chord, stream\n",
        "import pickle\n",
        "import os\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_Wirmg419co"
      },
      "source": [
        "def get_notes(path):\n",
        "\n",
        "    notes = []\n",
        "\n",
        "    for filename in os.listdir(path):\n",
        "          file = path + \"/\" + filename\n",
        "          print(\"Parsing\", file)\n",
        "        \n",
        "          midi = converter.parse(file)\n",
        "          need_parse = midi.flat.notes\n",
        "\n",
        "          for i in need_parse:\n",
        "            if isinstance(i, note.Note):\n",
        "                melody.append(str(i.pitch))\n",
        "            elif isinstance(i, chord.Chord):\n",
        "                melody.append([str(n) for n in i.pitches])"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "FXYMIagR2Ex4",
        "outputId": "ccbce9ea-19f1-41cb-e289-221237de351a"
      },
      "source": [
        "notes_from_here_please = \"/content/drive/My Drive/notebooks/music/training_songs\"\n",
        "notes = get_notes(notes_from_here_please)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parsing /content/drive/My Drive/notebooks/music/training_songs/breadknife.mid\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-8a3126433a22>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnotes_from_here_please\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/drive/My Drive/notebooks/music/training_songs\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnotes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_notes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnotes_from_here_please\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-2-d0e4f68eb42c>\u001b[0m in \u001b[0;36mget_notes\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     12\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mneed_parse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnote\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNote\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m                 \u001b[0mmelody\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpitch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mChord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                 \u001b[0mmelody\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpitches\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'melody' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ey42vV5G2H92"
      },
      "source": [
        "Replace durations (music21 package sometimes gives 7 or 21/3)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yA0S8N672Eva"
      },
      "source": [
        "durations = [x.replace('1/3', '0.25') for x in durations]\n",
        "durations = [x.replace('2/3', '0.75') for x in durations]\n",
        "durations = [x.replace('4/3', '1') for x in durations]\n",
        "durations = [x.replace('5/3', '1.25') for x in durations]\n",
        "durations = [x.replace('7/3', '2.25') for x in durations]\n",
        "durations = [x.replace('8/3', '2.5') for x in durations]\n",
        "durations = [x.replace('10/3', '3.25') for x in durations]\n",
        "durations = [x.replace('13/3', '4.25') for x in durations]\n",
        "durations = [x.replace('23/3', '7') for x in durations]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nrfao1I52Vz5"
      },
      "source": [
        "Define notes as a string list of each note in melody"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZxPUtMs2Esi"
      },
      "source": [
        "#define notes as a string list of each note in melody \n",
        "\n",
        "notes = []\n",
        "for i, j in enumerate(melody):\n",
        "  if isinstance(j, list): \n",
        "    for k in j:\n",
        "      notes.append(k)\n",
        "  else:\n",
        "    notes.append(j)\n",
        "\n",
        "def list_to_dict(x): \n",
        "    unique = sorted(set([item for item in x]))\n",
        "    print(len(unique),' unique notes put into dictionary')\n",
        "\n",
        "    Dict = { i : unique[i] for i in range(0, len(unique) ) }\n",
        "    print(Dict)\n",
        "\n",
        "    #Dict = dict((i, j) for j, i in enumerate(x))\n",
        "    return Dict\n",
        "\n",
        "notes_d = list_to_dict(notes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "syZuAYfK2Epw"
      },
      "source": [
        "melody[1:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FlKkGMKO2j8p"
      },
      "source": [
        "Create sparse matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5MTFIIi2EnW"
      },
      "source": [
        "#initialize sparse matrix\n",
        "l = []\n",
        "\n",
        "for i in notes_d.keys():\n",
        "  l.append([i])\n",
        "print('Each note has been given a row in matrix l')\n",
        "\n",
        "# === sparse matrix\n",
        "\n",
        "def sparse_matrix(l, melody, durations, notes_d):\n",
        "\n",
        "    print('Melody length is ', len(melody))\n",
        "    print('Start off with ', l)\n",
        "    stops, t = {}, 0\n",
        "\n",
        "    for index, n in enumerate(melody):\n",
        "\n",
        "        if isinstance(n, list):\n",
        "            __freeze_time = True\n",
        "        else:\n",
        "            __freeze_time = False\n",
        "\n",
        "        d = dict((k, v) for k, v in stops.items() if v < t)\n",
        "        #for understanding: print(n, __freeze_time)\n",
        "\n",
        "        if __freeze_time == True:\n",
        "            for note in n:\n",
        "                dur = durations[index]\n",
        "                m = int(float(dur) / 0.25)\n",
        "                for i, j in enumerate(l):\n",
        "                    if note != j[0] and j[0] not in n:\n",
        "                        for x in range(m):\n",
        "                            l[i].append(0)\n",
        "                    else:\n",
        "\n",
        "                        for x in range(m):\n",
        "                            l[i].append(1)\n",
        "                        stops[note] = m\n",
        "\n",
        "        elif __freeze_time == False:\n",
        "            dur = durations[index]\n",
        "            m = int(float(dur) / 0.25)\n",
        "            #for understanding: print(dur, m, n)\n",
        "            for i, j in enumerate(l):\n",
        "                if n != j[0]:\n",
        "                    for x in range(m):\n",
        "                        l[i].append(0)\n",
        "                else:\n",
        "                    for x in range(m):\n",
        "                        l[i].append(1)\n",
        "                    stops[n] = m\n",
        "        t +=1\n",
        "\n",
        "\n",
        "    print('Resulting l is', l, '\\n we will remove first note or replace it with integer value')\n",
        "    #prep for sparse matrix by cutting off first note?\n",
        "    for i in range(len(l)):\n",
        "        l[i][0] = notes_d[l[i][0]]\n",
        "\n",
        "    #might need to preserve note order for later..\n",
        "    # order_ = []\n",
        "    # for i in range(len(l)):\n",
        "    #     order_.append(l[i][0])\n",
        "    return l\n",
        "\n",
        "l = sparse_matrix(l, melody, durations, notes_d)\n",
        "\n",
        "from scipy.sparse import csr_matrix, csr_matrix\n",
        "\n",
        "import sys \n",
        "#print(np.array(l))\n",
        "#this doesn't work for autoencoder: sparse = csc_matrix(l)\n",
        "sparse = csr_matrix(l, dtype=np.int8).toarray()\n",
        "print('Sparse matrix of form m x n where m=note and n=duration stored in l')\n",
        "print(\"Memory utilised (bytes): \", sys.getsizeof(sparse))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TtvBIqXh2tw1"
      },
      "source": [
        "Notice that sparse is now sorted by col=0 (if note kept),"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_WNI3272Ekz"
      },
      "source": [
        "print(sparse.shape)\n",
        "sparse[0:2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pih99tGy2xKr"
      },
      "source": [
        "# Run *autoencoder*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bNTx0SgE24Sr"
      },
      "source": [
        "## Seeding & hyperparameters\n",
        "- Seed as to not get random result when training\n",
        "- Hyperparameters:\n",
        "  - sequence_length: how long your output song will be;\n",
        "  - input_sample: # of unique notes (rows in matrix);\n",
        "  - input_notes: how many notes you have in total (cols in matrix);\n",
        "  - input_dim: same as input_notes;\n",
        "  - latent_dim: the # of dimensions we \"scrunch down to\";\n",
        "  - epochs: # of epochs;\n",
        "  - learning_rate: learning rate."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wyjUfRNY223_"
      },
      "source": [
        "\"\"\" Seeding \"\"\"\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "\"\"\" Hyperparameters \"\"\"\n",
        "#Notes_ = Notes_[1:2000]\n",
        "Notes_ = np.array(sparse)\n",
        "print('Input shape: ', Notes_.shape)\n",
        "sequence_length = 1\n",
        "\n",
        "input_sample = Notes_.shape[0]\n",
        "print('input_sample (datasize) is the # of unique notes (# of rows in sparse matrix), ', input_sample)\n",
        "input_notes = Notes_.shape[1]\n",
        "input_dim = input_notes\n",
        "print('input_dim (# of cols in matrix, synonomous w/ length of song) are', input_dim)\n",
        "\n",
        "latent_dim = 2\n",
        "\n",
        "epochs = 200\n",
        "\n",
        "learning_rate = 0.000013"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5AfQ7Tjf3fUw"
      },
      "source": [
        "Run model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4nyAS5tT3iOl"
      },
      "source": [
        "Encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ouR8bdEg3hnd"
      },
      "source": [
        "##Encoder\n",
        "#EncInput = Input(shape = (number_of_samples))\n",
        "EncInput = Input(shape= (input_dim,))\n",
        "#shrink down to shape of latent dim\n",
        "Enc = Dense(latent_dim, activation = 'sigmoid')(EncInput)\n",
        "print('Encoder',Enc)\n",
        "encode = Model(EncInput, Enc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5bSDHxc3kM_"
      },
      "source": [
        "Decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70g75q-73jn5"
      },
      "source": [
        "##Decoder\n",
        "#start @ shape of latent dim\n",
        "DecInput = Input(shape= (latent_dim,))\n",
        "#go back out to input_dim\n",
        "Dec = Dense(input_dim, activation = 'sigmoid')(DecInput)\n",
        "print('Decoder',Dec)\n",
        "decode = Model(DecInput, Dec)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wm-_WMMk3mV6"
      },
      "source": [
        "Autoencoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-tML30ys3lzb"
      },
      "source": [
        "##Autoencoder\n",
        "autoencoder = Model(EncInput, decode(Enc))\n",
        "\n",
        "#Try different learning rates, batch sizes, dropout layer (?), add another layer (if more data)? \n",
        "#autoencoder.compile(loss = 'binary_crossentropy', optimizer=RMSprop(learning_rate=0.00013))\n",
        "autoencoder.compile(loss = 'binary_crossentropy', optimizer='adam')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rFW5buqL3xpo"
      },
      "source": [
        "# Generation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRqEy-7e30AB"
      },
      "source": [
        "Approach: use a random \"starting point\" & decode that"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVyT2rNS2EiW"
      },
      "source": [
        "D_MEl = decode([np.random.normal(size =(1, latent_dim))]).numpy().reshape(input_notes) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rUZKGOa2Ef2"
      },
      "source": [
        "print('durations?', D_MEl)\n",
        "print('nonono want a 48 x 3809 shape honestly you\"ve gotta be joshin me...')\n",
        "\n",
        "# == reconstruction of song ... == #\n",
        "\n",
        "prepped = [round(x*4)/4 for x in D_MEl]\n",
        "print(prepped)\n",
        "\n",
        "def find_key(input_dict, value):\n",
        "    return next((k for k, v in input_dict.items() if v == value), None)\n",
        "\n",
        "__arr = []\n",
        "for i in range(78): \n",
        "  q = find_key(notes_d, i)\n",
        "  #__durs = []\n",
        "  # for j in prepped:\n",
        "  #   d = duration.Duration(j)\n",
        "  __arr.append([note.Note(q, quarterLength=j) for j in prepped])\n",
        "  #   __arr.append([note.Note(q, duration=d)])\n",
        "print('single melody created in __arr')\n",
        "print(__arr[1:10][1:10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MyOZ4ac12Ec9"
      },
      "source": [
        "print('inputting into stream object, s_obj ... \\n')\n",
        "s_obj = stream.Stream()\n",
        "s_obj.append(instrument.Piano())\n",
        "\n",
        "for i in __arr[1:10][1:10]: #for each note\n",
        "    print([y.duration.quarterLength for y in i])\n",
        "    print(len(i), i)\n",
        "    #take the \"stack\" of notes as psuedo-chords\n",
        "    s_obj.append(chord.Chord([j for j in i]))\n",
        "\n",
        "print('input complete, generating as \"generated.mid\"...')\n",
        "s_obj.write('midi', fp='/content/drive/My Drive/notebooks/music'+'/generated.mid')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e870JCGY2EWI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}